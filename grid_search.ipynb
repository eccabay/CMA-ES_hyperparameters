{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "employed-throat",
   "metadata": {
    "id": "employed-throat"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "european-transparency",
   "metadata": {
    "id": "european-transparency"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hired-study",
   "metadata": {
    "id": "hired-study"
   },
   "outputs": [],
   "source": [
    "class GridSearch:\n",
    "    \n",
    "    def __init__(self, estimators, estimator_params):\n",
    "        self.estimators = estimators\n",
    "        self.estimator_params = estimator_params\n",
    "        self.results = {}\n",
    "        \n",
    "    def search_single(self, dataset):\n",
    "        \"\"\" Perform a grid search using all estimators on a single dataset\n",
    "        \n",
    "        Args:\n",
    "            dataset (tuple): a 4-tuple of X_train, X_test, y_train, y_test\n",
    "        Returns:\n",
    "            results dictionary with the best score, training time, and best \n",
    "            parameters for each estimator\n",
    "        \"\"\"\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = dataset\n",
    "        results = {}\n",
    "        \n",
    "        for estimator_name, estimator in self.estimators.items():\n",
    "            print(estimator_name)\n",
    "            params = self.estimator_params[estimator_name]\n",
    "            grid_search = GridSearchCV(estimator, params)\n",
    "            \n",
    "            start = time.time()\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            end = time.time()\n",
    "            \n",
    "            test_score = grid_search.score(X_test, y_test)\n",
    "            \n",
    "            result_data = {'best_score': grid_search.best_score_,\n",
    "                           'best_params': grid_search.best_params_,\n",
    "                           'total_time': end-start,\n",
    "                           'test_score': test_score}\n",
    "            \n",
    "            results[estimator] = result_data\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def search(self, datasets):\n",
    "        for dataset_name, dataset in datasets.items():\n",
    "            print(f'Searching {dataset_name}')\n",
    "            dataset_results = self.search_single(dataset)\n",
    "            self.results[dataset_name] = dataset_results\n",
    "            print()\n",
    "            \n",
    "        return self.results\n",
    "    \n",
    "    def print_results(self):\n",
    "        complete_search_time = 0\n",
    "        \n",
    "        # Find the estimator that performed best for each dataset\n",
    "        for dataset_name, dataset_results in self.results.items():\n",
    "            total_time = [estimator_results['total_time'] for estimator_results in dataset_results.values()]\n",
    "            time_dict = {estimator_name: estimator_results['total_time'] for estimator_name, estimator_results in dataset_results.items()}\n",
    "            dataset_time = sum(total_time)\n",
    "            complete_search_time += dataset_time\n",
    "            \n",
    "            # Get a mapping from the best score to the estimator\n",
    "            scores = [estimator_results['best_score'] for estimator_results in dataset_results.values()]\n",
    "            score_to_estimator = {dataset_results[estimator]['best_score']: estimator for estimator in dataset_results.keys()}\n",
    "            \n",
    "            best_score = max(scores)\n",
    "            best_estimator = score_to_estimator[best_score]\n",
    "            best_params = dataset_results[best_estimator]['best_params']\n",
    "            best_test_score = dataset_results[best_estimator]['test_score']\n",
    "            \n",
    "            print(f'Dataset {dataset_name}: \\nBest Estimator: {best_estimator} \\n Params: {best_params} \\nScore: {best_score} \\nTotal time:{dataset_time} \\nTesting score:{best_test_score} \\nTime Dict:{time_dict}\\n\\n')\n",
    "        \n",
    "        results_df = pd.DataFrame(self.results)\n",
    "        print('Grid Search total time:', complete_search_time)\n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "satellite-engagement",
   "metadata": {
    "id": "satellite-engagement"
   },
   "outputs": [],
   "source": [
    "classification_estimators = {'Logistic Regression': LogisticRegression(),\n",
    "                             'KNN': KNeighborsClassifier(),\n",
    "                             'Decision Tree': DecisionTreeClassifier(),\n",
    "                             'AdaBoost': AdaBoostClassifier(),}\n",
    "#                             'MLP': MLPClassifier()}\n",
    "classification_parameters = {'Logistic Regression': {'C': np.arange(0.1, 1.9, 0.2), 'max_iter': np.arange(25, 325, 25), 'fit_intercept': [False, True]},\n",
    "                             'KNN': {'n_neighbors': np.arange(2, 13, 1), 'leaf_size': np.arange(10, 80, 5)},\n",
    "                             'Decision Tree': {'min_samples_split': np.arange(2, 6, 1), 'max_depth': np.arange(25, 275, 25)},\n",
    "                             'AdaBoost': {'n_estimators': np.arange(10, 65, 5), 'learning_rate': np.arange(0.25, 1.75, 0.25)},}\n",
    "#                             'MLP': {'activation': ['logistic', 'tanh', 'relu'], 'max_iter': np.arange(100, 300, 50)}}\n",
    "\n",
    "regression_estimators = {'Linear Regression': LinearRegression(),\n",
    "                         'KNN': KNeighborsRegressor(),\n",
    "                         'Decision Tree': DecisionTreeRegressor(),\n",
    "                         'AdaBoost': AdaBoostRegressor(),}\n",
    "#                         'MLP': MLPRegressor()}\n",
    "regression_parameters = {'Linear Regression': {'fit_intercept': [False, True]},\n",
    "                         'KNN': {'n_neighbors': np.arange(2, 13, 1), 'leaf_size': np.arange(10, 80, 5)},\n",
    "                         'Decision Tree': {'min_samples_split': np.arange(2, 6, 1), 'max_depth': np.arange(25, 275, 25)},\n",
    "                         'AdaBoost': {'n_estimators': np.arange(10, 65, 5), 'learning_rate': np.arange(0.25, 1.75, 0.25)},}\n",
    "#                         'MLP': {'activation': ['logistic', 'tanh', 'relu'], 'max_iter': np.arange(100, 300, 50)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "editorial-northeast",
   "metadata": {
    "id": "editorial-northeast",
    "outputId": "b1cb588c-3d38-4c39-89a7-be5a49134fa3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching heart_attack\n",
      "Logistic Regression\n",
      "KNN\n",
      "Decision Tree\n",
      "AdaBoost\n",
      "\n",
      "Searching stroke\n",
      "Logistic Regression\n",
      "KNN\n",
      "Decision Tree\n",
      "AdaBoost\n",
      "\n",
      "Searching telecom\n",
      "Logistic Regression\n",
      "KNN\n",
      "Decision Tree\n",
      "AdaBoost\n",
      "\n",
      "Dataset heart_attack: \n",
      "Best Estimator: LogisticRegression() \n",
      " Params: {'C': 1.1000000000000003, 'fit_intercept': True, 'max_iter': 75} \n",
      "Score: 0.8306122448979592 \n",
      "Total time:122.6443600654602 \n",
      "Testing score:0.8852459016393442 \n",
      "Time Dict:{LogisticRegression(): 75.49915957450867, KNeighborsClassifier(): 10.380993843078613, DecisionTreeClassifier(): 2.145153045654297, AdaBoostClassifier(): 34.61905360221863}\n",
      "\n",
      "\n",
      "Dataset stroke: \n",
      "Best Estimator: LogisticRegression() \n",
      " Params: {'C': 1.3000000000000003, 'fit_intercept': True, 'max_iter': 100} \n",
      "Score: 0.9547455806172621 \n",
      "Total time:234.19476532936096 \n",
      "Testing score:0.9393346379647749 \n",
      "Time Dict:{LogisticRegression(): 135.09029006958008, KNeighborsClassifier(): 43.89105558395386, DecisionTreeClassifier(): 3.1580138206481934, AdaBoostClassifier(): 52.05540585517883}\n",
      "\n",
      "\n",
      "Dataset telecom: \n",
      "Best Estimator: LogisticRegression() \n",
      " Params: {'C': 0.5000000000000001, 'fit_intercept': True, 'max_iter': 75} \n",
      "Score: 0.7999175398066767 \n",
      "Total time:297.86724615097046 \n",
      "Testing score:0.8005008347245409 \n",
      "Time Dict:{LogisticRegression(): 137.04021787643433, KNeighborsClassifier(): 102.60134530067444, DecisionTreeClassifier(): 4.007979393005371, AdaBoostClassifier(): 54.21770358085632}\n",
      "\n",
      "\n",
      "Grid Search total time: 654.7063715457916\n"
     ]
    }
   ],
   "source": [
    "binary_data = load_data.load_binary()\n",
    "binary_grid_search = GridSearch(classification_estimators, classification_parameters)\n",
    "\n",
    "binary_grid_search.search(binary_data)\n",
    "binary_results = binary_grid_search.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cardiac-tenant",
   "metadata": {
    "id": "cardiac-tenant",
    "outputId": "c1ab1be2-e805-4efe-b50a-ac00b7fe430c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching california_housing\n",
      "Linear Regression\n",
      "KNN\n",
      "Decision Tree\n",
      "AdaBoost\n",
      "\n",
      "Searching melbourne_housing\n",
      "Linear Regression\n",
      "KNN\n",
      "Decision Tree\n",
      "AdaBoost\n",
      "\n",
      "Searching world_happiness\n",
      "Linear Regression\n",
      "KNN\n",
      "Decision Tree\n",
      "AdaBoost\n",
      "\n",
      "Dataset california_housing: \n",
      "Best Estimator: DecisionTreeRegressor() \n",
      " Params: {'max_depth': 225, 'min_samples_split': 5} \n",
      "Score: 0.6282821205770821 \n",
      "Total time:396.8780517578125 \n",
      "Testing score:0.6285227023873552 \n",
      "Time Dict:{LinearRegression(): 0.08472180366516113, KNeighborsRegressor(): 35.20700478553772, DecisionTreeRegressor(): 33.241832971572876, AdaBoostRegressor(): 328.34449219703674}\n",
      "\n",
      "\n",
      "Dataset melbourne_housing: \n",
      "Best Estimator: DecisionTreeRegressor() \n",
      " Params: {'max_depth': 25, 'min_samples_split': 5} \n",
      "Score: 0.6281231108838001 \n",
      "Total time:833.4771201610565 \n",
      "Testing score:0.6966406496123827 \n",
      "Time Dict:{LinearRegression(): 0.16603541374206543, KNeighborsRegressor(): 442.3555247783661, DecisionTreeRegressor(): 22.866878509521484, AdaBoostRegressor(): 368.0886814594269}\n",
      "\n",
      "\n",
      "Dataset world_happiness: \n",
      "Best Estimator: AdaBoostRegressor() \n",
      " Params: {'learning_rate': 1.25, 'n_estimators': 60} \n",
      "Score: 0.7739661850014542 \n",
      "Total time:55.97839856147766 \n",
      "Testing score:0.7159321112851114 \n",
      "Time Dict:{LinearRegression(): 0.12693381309509277, KNeighborsRegressor(): 11.978854179382324, DecisionTreeRegressor(): 2.828442335128784, AdaBoostRegressor(): 41.04416823387146}\n",
      "\n",
      "\n",
      "Grid Search total time: 1286.3335704803467\n"
     ]
    }
   ],
   "source": [
    "regression_data = load_data.load_regression()\n",
    "regression_grid_search = GridSearch(regression_estimators, regression_parameters)\n",
    "\n",
    "regression_grid_search.search(regression_data)\n",
    "regression_results = regression_grid_search.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "middle-relay",
   "metadata": {
    "id": "middle-relay",
    "outputId": "0181c370-9027-4599-f942-7cb09a713d5e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching mnist\n",
      "Logistic Regression\n",
      "KNN\n",
      "Decision Tree\n",
      "AdaBoost\n",
      "\n",
      "Searching forest_covertypes\n",
      "Logistic Regression\n",
      "KNN\n",
      "Decision Tree\n",
      "AdaBoost\n",
      "\n",
      "Searching kepler_exoplanets\n",
      "Logistic Regression\n",
      "KNN\n",
      "Decision Tree\n",
      "AdaBoost\n",
      "\n",
      "Dataset mnist: \n",
      "Best Estimator: KNeighborsClassifier() \n",
      " Params: {'leaf_size': 10, 'n_neighbors': 3} \n",
      "Score: 0.9846883468834691 \n",
      "Total time:632.2646894454956 \n",
      "Testing score:0.9833333333333333 \n",
      "Time Dict:{LogisticRegression(): 515.1806199550629, KNeighborsClassifier(): 31.34954833984375, DecisionTreeClassifier(): 6.331221580505371, AdaBoostClassifier(): 79.40329957008362}\n",
      "\n",
      "\n",
      "Dataset forest_covertypes: \n",
      "Best Estimator: KNeighborsClassifier() \n",
      " Params: {'leaf_size': 10, 'n_neighbors': 2} \n",
      "Score: 0.80325 \n",
      "Total time:3408.58008146286 \n",
      "Testing score:0.817 \n",
      "Time Dict:{LogisticRegression(): 2446.368030309677, KNeighborsClassifier(): 721.2202088832855, DecisionTreeClassifier(): 27.567227125167847, AdaBoostClassifier(): 213.42461514472961}\n",
      "\n",
      "\n",
      "Dataset kepler_exoplanets: \n",
      "Best Estimator: AdaBoostClassifier() \n",
      " Params: {'learning_rate': 0.25, 'n_estimators': 10} \n",
      "Score: 0.9851002591326102 \n",
      "Total time:991.6568677425385 \n",
      "Testing score:0.9822268687924726 \n",
      "Time Dict:{LogisticRegression(): 301.71534061431885, KNeighborsClassifier(): 257.42253971099854, DecisionTreeClassifier(): 38.755898237228394, AdaBoostClassifier(): 393.7630891799927}\n",
      "\n",
      "\n",
      "Grid Search total time: 5032.501638650894\n"
     ]
    }
   ],
   "source": [
    "multiclass_data = load_data.load_multiclass()\n",
    "multiclass_grid_search = GridSearch(classification_estimators, classification_parameters)\n",
    "\n",
    "multiclass_grid_search.search(multiclass_data)\n",
    "multiclass_results = multiclass_grid_search.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-pound",
   "metadata": {
    "id": "rubber-pound"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "grid_search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
