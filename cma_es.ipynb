{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"cma_es.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"code","metadata":{"id":"charming-negative"},"source":["import math\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.linear_model import LogisticRegression, LinearRegression\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n","from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n","\n","from sklearn.model_selection import KFold\n","\n","import load_data"],"id":"charming-negative","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"encouraging-senegal"},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"id":"encouraging-senegal","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"searching-ballot"},"source":["def addouter(C, b, factor=1):\n","    for i, row in enumerate(C):\n","        for j in range(len(row)):\n","            row[j] += factor * b[i] * b[j]\n","    return C\n","\n","def assert_symmetric(C):\n","    for i in range(len(C)):\n","        for j in range(i):\n","            C[i][j] = C[j][i] = (C[i][j] + C[j][i])/2\n","    return C"],"id":"searching-ballot","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"762b5f6c"},"source":["def get_args(params, scale, classifier):    \n","    \n","    args = {arg: params[c]*10**scale[arg] for c, arg in enumerate(scale.keys())}\n","    \n","    # Cheating a bit to deal with discrete arguments and integer\n","    if classifier == LogisticRegression or classifier == LinearRegression:\n","        args['fit_intercept'] = args['fit_intercept'] > 0.5\n","    if classifier == MLPClassifier or classifier == MLPRegressor:\n","        args['max_iter'] = math.ceil(args['max_iter'])\n","        if args['activation'] < 0.3333:\n","            args['activation'] = 'logistic'\n","        elif args['activation'] > 0.6667:\n","            args['activation'] = 'relu'\n","        else:\n","            args['activation'] = 'tanh'\n","    if classifier == KNeighborsClassifier or classifier == KNeighborsRegressor:\n","        args['n_neighbors'] = max(round(args['n_neighbors']), 1)\n","    if classifier == DecisionTreeClassifier or classifier == DecisionTreeRegressor:\n","        args['min_samples_split'] = float(args['min_samples_split'])\n","        if args['min_samples_split'] > 1:\n","            args['min_samples_split'] = math.ceil(args['min_samples_split'])\n","    if classifier == AdaBoostClassifier or classifier == AdaBoostRegressor:\n","        args['n_estimators'] = max(round(args['n_estimators']), 1)\n","        \n","    return args"],"id":"762b5f6c","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"painful-notion"},"source":["def fitness(X, y, candidate, scale, classifier):\n","    \n","    args = get_args(candidate, scale, classifier)\n","    \n","    scores = []\n","    kf = KFold(n_splits=3)\n","    for train_index, test_index in kf.split(X):\n","        X_train, X_test = X[train_index], X[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","    \n","        clf = classifier(**args)\n","        clf.fit(X_train, y_train)\n","        scores.append(clf.score(X_test, y_test))\n","    \n","    return -np.mean(scores)   "],"id":"painful-notion","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"asian-hindu"},"source":["class CMA_ES:\n","    def __init__(self, xstart, scale, clf, max_iter=10, lamb=10, sigma=1):\n","        self.xstart = xstart\n","        self.scale = scale\n","        self.clf = clf\n","        self.lamb = lamb\n","        self.sigma = sigma\n","        \n","        self.dim = len(xstart)\n","        self.maxeval = max_iter*self.lamb\n","        \n","        self.initialize_parameters()\n","        \n","    def initialize_parameters(self):\n","        N = self.dim\n","        self.chiN = N**0.5 * (1 - 1./(4*N) + 1. / (21 * N**2))\n","        self.mu = int(self.lamb/2)\n","        \n","        weights = [math.log((self.lamb+1)/2) - math.log(i) for i in range(1, self.lamb+1)]\n","        self.weights = np.array(weights)/sum(weights[:self.mu])\n","        self.mueff = sum(self.weights)**2 / sum(self.weights**2)\n","        \n","        # Set Adaptation parameters\n","        self.cc = (4 + self.mueff/N) / (N+4 + 2 * self.mueff/N)\n","        self.cs = (self.mueff + 2) / (N + self.mueff + 5)\n","        self.c1 = 2 / ((N + 1.3)**2 + self.mueff)\n","        self.cmu = min([1-self.c1, 2 * (self.mueff - 2 + 1/self.mueff) / ((N+2)**2 + self.mueff)])\n","        self.damps = 2 * self.mu/self.lamb + 0.3 + self.cs\n","        \n","        self.lazy_gap_evals = 0.5 * N * self.lamb * (self.c1+self.cmu)**-1 / N**2\n","        self.update_eval = 0\n","        \n","    def initialize_variables(self, X, y):\n","        self.X = X.to_numpy()\n","        if isinstance(y, pd.Series):\n","            self.y = y.to_numpy()\n","        else:\n","            self.y = y\n","        self.xmean = self.xstart\n","        self.pc = self.dim * [0]\n","        self.ps = self.dim * [0]\n","        \n","        self.B = np.eye(self.dim)\n","        self.D = self.dim * [1]\n","        self.C = np.eye(self.dim)\n","        self.invsqrtC = np.eye(self.dim)\n","        \n","        self.counteval = 0\n","        self.best = [self.xmean]\n","        self.best_fitness = [-fitness(self.X, self.y, self.best[0], self.scale, self.clf)]\n","        \n","    def stop(self):\n","        if self.counteval >= self.maxeval:\n","            return True\n","        if len(self.best_fitness) >= 2:\n","            improvement = abs(self.best_fitness[-1] - self.best_fitness[-2])\n","            if improvement < 10e-9:\n","                print(f'Stopping early after {int(self.counteval/self.lamb)} iteration(s)')\n","                return True\n","        return False\n","    \n","    def propose_candidates(self):\n","        candidates = []\n","        for i in range(self.lamb):\n","            self.counteval += 1\n","            x = np.random.multivariate_normal(self.xmean, self.sigma*self.C)\n","            \n","            # None of the possible values can be negative, so just take the absolute value\n","            x = [abs(arg) for arg in x]\n","            \n","            candidates.append(x)\n","        return candidates\n","    \n","    def sort_candidates(self, X):\n","        candidate_fitness = []\n","        for candidate in X:\n","            candidate_fitness.append(fitness(self.X, self.y, candidate, self.scale, self.clf))\n","            \n","        order = np.array(candidate_fitness).argsort()\n","        X = np.array(X)[order]\n","        \n","        self.best.append(X[0])\n","        self.best_fitness.append(-min(candidate_fitness))\n","        return X\n","    \n","    def update_variables(self, X):\n","        \n","        xold = self.xmean\n","        self.xmean = np.dot(np.transpose(X[:self.mu]), self.weights[:self.mu])\n","        \n","        y = np.subtract(self.xmean, xold)\n","        z = np.dot(self.invsqrtC, y)\n","        csn = (self.cs * (2 - self.cs) * self.mueff)**0.5 / self.sigma\n","        for i in range(self.dim):\n","            self.ps[i] - (1-self.cs) * self.ps[i] + csn * z[i]\n","        ccn = (self.cc * (2-self.cc) * self.mueff)**0.5 / self.sigma\n","        \n","        hsig = (sum(x**2 for x in self.ps) / self.dim / (1-(1-self.cs)**(2*self.counteval/self.lamb)) < 2+4./(self.dim+1))\n","        for i in range(self.dim):\n","            self.pc[i] = (1 - self.cc) * self.pc[i] + ccn * hsig * y[i]\n","        \n","        c1a = self.c1 * (1 - (1-hsig**2) * self.cc * (2-self.cc))\n","        self.C = (1 - c1a - self.cmu * sum(self.weights))*self.C\n","        self.C = addouter(self.C, self.pc, self.c1)\n","        for k, wk in enumerate(self.weights):\n","            if wk < 0:\n","                dx = np.subtract(X[k], xold)\n","                wk *= self.dim * (self.sigma / sum(xi**2 for xi in np.dot(self.invsqrtC, dx))**0.5)**2\n","            self.C = addouter(self.C, np.subtract(X[k], xold), wk * self.cmu / self.sigma**2)\n","            \n","        if self.counteval > self.update_eval + self.lazy_gap_evals:\n","            self.C = assert_symmetric(self.C)\n","            self.D, self.B = np.linalg.eig(self.C)\n","            for i in range(len(self.C)):\n","                for j in range(i+1):\n","                    self.invsqrtC[i][j] = self.invsqrtC[j][i] = sum(self.B[i][k] * self.B[j][k] / self.D[k]**0.5 for k in range(len(self.C)))\n","            self.update_eval = self.counteval\n","            \n","        cn, sum_square_ps = self.cs / self.damps, sum(x**2 for x in self.ps)\n","        self.sigma *= math.exp(min(1, cn * (sum_square_ps / self.dim - 1) / 2))\n","        \n","    def run(self, X, y):\n","        self.initialize_variables(X, y)\n","        \n","        while not self.stop():\n","            X = self.propose_candidates()\n","            X = self.sort_candidates(X)\n","            self.update_variables(X)\n","            \n","        return self.best_fitness\n","    \n","    def get_best_params(self):\n","        max_score = self.best_fitness[0]\n","        max_params = self.best[0]\n","        for i in range(len(self.best)):\n","            if self.best_fitness[i] >= max_score:\n","                max_score = self.best_fitness[i]\n","                max_params = self.best[i]\n","        return max_score, max_params"],"id":"asian-hindu","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ideal-depth"},"source":["class CMAESSearch:\n","    \n","    def __init__(self, estimators, estimator_params):\n","        self.estimators = estimators\n","        self.estimator_params = estimator_params\n","        self.results = {}\n","        \n","    def search_single(self, dataset):\n","        \"\"\" Perform a grid search using all estimators on a single dataset\n","        \n","        Args:\n","            dataset (tuple): a 4-tuple of X_train, X_test, y_train, y_test\n","        Returns:\n","            results dictionary with the best score, training time, and best \n","            parameters for each estimator\n","        \"\"\"\n","        \n","        X_train, X_test, y_train, y_test = dataset\n","        results = {}\n","        \n","        for estimator_name, estimator in self.estimators.items():\n","            print(estimator_name)\n","            params = self.estimator_params[estimator_name]\n","            cmaes = CMA_ES(params['default'], params['scale'], estimator)\n","            \n","            start = time.time()\n","            cmaes.run(X_train, y_train)\n","            end = time.time()\n","            \n","            best_score, best_params = cmaes.get_best_params()\n","            \n","            best_args = get_args(best_params, params['scale'], estimator)\n","            best_estimator = estimator(**best_args)\n","            best_estimator.fit(X_train, y_train)\n","            test_score = best_estimator.score(X_test, y_test)\n","            \n","            result_data = {'best_score': best_score,\n","                           'best_params': best_args,\n","                           'total_time': end-start,\n","                           'test_score': test_score}\n","            \n","            results[estimator] = result_data\n","            \n","        return results\n","    \n","    def search(self, datasets):\n","        for dataset_name, dataset in datasets.items():\n","            print(f'Searching {dataset_name}')\n","            dataset_results = self.search_single(dataset)\n","            self.results[dataset_name] = dataset_results\n","            print()\n","            \n","        return self.results\n","    \n","    def print_results(self):\n","        complete_search_time = 0\n","        \n","        # Find the estimator that performed best for each dataset\n","        for dataset_name, dataset_results in self.results.items():\n","            total_time = [estimator_results['total_time'] for estimator_results in dataset_results.values()]\n","            time_dict = {estimator_name: estimator_results['total_time'] for estimator_name, estimator_results in dataset_results.items()}\n","            dataset_time = sum(total_time)\n","            complete_search_time += dataset_time\n","            \n","            # Get a mapping from the best score to the estimator\n","            scores = [estimator_results['best_score'] for estimator_results in dataset_results.values()]\n","            score_to_estimator = {dataset_results[estimator]['best_score']: estimator for estimator in dataset_results.keys()}\n","            \n","            best_score = max(scores)\n","            best_estimator = score_to_estimator[best_score]            \n","            best_params = dataset_results[best_estimator]['best_params']\n","            best_test_score = dataset_results[best_estimator]['test_score']\n","            \n","            print(f'Dataset {dataset_name}: \\nBest Estimator: {best_estimator} \\n Params: {best_params} \\nScore: {best_score} \\nTotal time:{dataset_time} \\nTesting score:{best_test_score} \\nTime Dict:{time_dict}\\n\\n')\n","        \n","        results_df = pd.DataFrame(self.results)\n","        print('Grid Search total time:', complete_search_time)\n","        return results_df"],"id":"ideal-depth","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sudden-flavor"},"source":["classification_estimators = {'Logistic Regression': LogisticRegression,\n","                             'KNN': KNeighborsClassifier,\n","                             'Decision Tree': DecisionTreeClassifier,\n","                             'AdaBoost': AdaBoostClassifier}\n","classification_parameters = {'Logistic Regression': {'default': [1, 1, 7.5],\n","                                                     'scale': {'C': 0, 'max_iter': 2, 'fit_intercept': -1}},\n","                             'KNN': {'default': [5, 3],\n","                                     'scale': {'n_neighbors': 0, 'leaf_size': 1}},\n","                             'Decision Tree': {'default': [2, 15],\n","                                               'scale': {'min_samples_split': 0, 'max_depth': 1}},\n","                             'AdaBoost': {'default': [5, 10],\n","                                          'scale': {'n_estimators': 1, 'learning_rate': -1}}}\n","\n","regression_estimators = {'Linear Regression': LinearRegression,\n","                         'KNN': KNeighborsRegressor,\n","                         'Decision Tree': DecisionTreeRegressor,\n","                         'AdaBoost': AdaBoostRegressor,}\n","regression_parameters = {'Linear Regression': {'default': [7.5],\n","                                               'scale': {'fit_intercept': -1}},\n","                         'KNN': {'default': [5, 3],\n","                                     'scale': {'n_neighbors': 0, 'leaf_size': 1}},\n","                         'Decision Tree': {'default': [2, 15],\n","                                           'scale': {'min_samples_split': 0, 'max_depth': 1}},\n","                         'AdaBoost': {'default': [5, 10],\n","                                      'scale': {'n_estimators':6'learning_rate': -1}}}"],"id":"sudden-flavor","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7agdpYFCq-Io"},"source":["binary_data = load_data.load_binary()\n","binary_grid_search = CMAESSearch(classification_estimators, classification_parameters)\n","\n","binary_grid_search.search(binary_data) \n","binary_results = binary_grid_search.print_results()"],"id":"7agdpYFCq-Io","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e0eb8acf","outputId":"067d3f91-3a84-423c-bafa-f1963910d4ee"},"source":["regression_data = load_data.load_regression()\n","regression_grid_search = CMAESSearch(regression_estimators, regression_parameters)\n","\n","regression_grid_search.search(regression_data) \n","regression_grid_search.print_results()"],"id":"e0eb8acf","execution_count":null,"outputs":[{"output_type":"stream","text":["Dataset california_housing: \n","Best Estimator: <class 'sklearn.tree._classes.DecisionTreeRegressor'> \n"," Params: {'min_samples_split': 20, 'max_depth': 164.75119177399168} \n","Score: 0.6669617209284268 \n","Total time:286.11477613449097 \n","Testing score:0.6891259025377072 \n","Time Dict:{<class 'sklearn.linear_model._base.LinearRegression'>: 0.13132405281066895, <class 'sklearn.neighbors._regression.KNeighborsRegressor'>: 8.299878358840942, <class 'sklearn.tree._classes.DecisionTreeRegressor'>: 34.90364217758179, <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>: 242.77993154525757}\n","\n","\n","Dataset melbourne_housing: \n","Best Estimator: <class 'sklearn.tree._classes.DecisionTreeRegressor'> \n"," Params: {'min_samples_split': 0.014756092538863896, 'max_depth': 160.27228142977458} \n","Score: 0.6565220457265545 \n","Total time:172.76335334777832 \n","Testing score:0.6973340219647486 \n","Time Dict:{<class 'sklearn.linear_model._base.LinearRegression'>: 0.16733789443969727, <class 'sklearn.neighbors._regression.KNeighborsRegressor'>: 49.56901717185974, <class 'sklearn.tree._classes.DecisionTreeRegressor'>: 23.808298110961914, <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>: 99.21870017051697}\n","\n","\n","Dataset world_happiness: \n","Best Estimator: <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'> \n"," Params: {'n_estimators': 58, 'learning_rate': 1.0411757165100395} \n","Score: 0.7903462655546128 \n","Total time:30.389525890350342 \n","Testing score:0.7375307032102045 \n","Time Dict:{<class 'sklearn.linear_model._base.LinearRegression'>: 0.041023969650268555, <class 'sklearn.neighbors._regression.KNeighborsRegressor'>: 0.12643170356750488, <class 'sklearn.tree._classes.DecisionTreeRegressor'>: 0.38392043113708496, <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>: 29.838149785995483}\n","\n","\n","Grid Search total time: 489.26765537261963\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>california_housing</th>\n","      <th>melbourne_housing</th>\n","      <th>world_happiness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>&lt;class 'sklearn.linear_model._base.LinearRegression'&gt;</th>\n","      <td>{'best_score': 0.6110921251096771, 'best_param...</td>\n","      <td>{'best_score': -0.044998716689544395, 'best_pa...</td>\n","      <td>{'best_score': 0.7404068030591904, 'best_param...</td>\n","    </tr>\n","    <tr>\n","      <th>&lt;class 'sklearn.neighbors._regression.KNeighborsRegressor'&gt;</th>\n","      <td>{'best_score': 0.1252408027018478, 'best_param...</td>\n","      <td>{'best_score': 0.5188455495085263, 'best_param...</td>\n","      <td>{'best_score': 0.6261647021338919, 'best_param...</td>\n","    </tr>\n","    <tr>\n","      <th>&lt;class 'sklearn.tree._classes.DecisionTreeRegressor'&gt;</th>\n","      <td>{'best_score': 0.6669617209284268, 'best_param...</td>\n","      <td>{'best_score': 0.6565220457265545, 'best_param...</td>\n","      <td>{'best_score': 0.6750782194363795, 'best_param...</td>\n","    </tr>\n","    <tr>\n","      <th>&lt;class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'&gt;</th>\n","      <td>{'best_score': 0.5522534393640788, 'best_param...</td>\n","      <td>{'best_score': 0.48764285967254306, 'best_para...</td>\n","      <td>{'best_score': 0.7903462655546128, 'best_param...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                   california_housing  \\\n","<class 'sklearn.linear_model._base.LinearRegres...  {'best_score': 0.6110921251096771, 'best_param...   \n","<class 'sklearn.neighbors._regression.KNeighbor...  {'best_score': 0.1252408027018478, 'best_param...   \n","<class 'sklearn.tree._classes.DecisionTreeRegre...  {'best_score': 0.6669617209284268, 'best_param...   \n","<class 'sklearn.ensemble._weight_boosting.AdaBo...  {'best_score': 0.5522534393640788, 'best_param...   \n","\n","                                                                                    melbourne_housing  \\\n","<class 'sklearn.linear_model._base.LinearRegres...  {'best_score': -0.044998716689544395, 'best_pa...   \n","<class 'sklearn.neighbors._regression.KNeighbor...  {'best_score': 0.5188455495085263, 'best_param...   \n","<class 'sklearn.tree._classes.DecisionTreeRegre...  {'best_score': 0.6565220457265545, 'best_param...   \n","<class 'sklearn.ensemble._weight_boosting.AdaBo...  {'best_score': 0.48764285967254306, 'best_para...   \n","\n","                                                                                      world_happiness  \n","<class 'sklearn.linear_model._base.LinearRegres...  {'best_score': 0.7404068030591904, 'best_param...  \n","<class 'sklearn.neighbors._regression.KNeighbor...  {'best_score': 0.6261647021338919, 'best_param...  \n","<class 'sklearn.tree._classes.DecisionTreeRegre...  {'best_score': 0.6750782194363795, 'best_param...  \n","<class 'sklearn.ensemble._weight_boosting.AdaBo...  {'best_score': 0.7903462655546128, 'best_param...  "]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"synthetic-chain","outputId":"e10db923-cae3-4e20-f6b5-3202ec98888d"},"source":["multiclass_data = load_data.load_multiclass()\n","multiclass_grid_search = CMAESSearch(classification_estimators, classification_parameters)\n","\n","multiclass_grid_search.search(multiclass_data) \n","multiclass_grid_search.print_results()"],"id":"synthetic-chain","execution_count":null,"outputs":[{"output_type":"stream","text":["Dataset mnist: \n","Best Estimator: <class 'sklearn.neighbors._classification.KNeighborsClassifier'> \n"," Params: {'n_neighbors': 5, 'leaf_size': 24.8611268924791} \n","Score: 0.9805149617258176 \n","Total time:142.37768936157227 \n","Testing score:0.9861111111111112 \n","Time Dict:{<class 'sklearn.linear_model._logistic.LogisticRegression'>: 45.634217500686646, <class 'sklearn.neighbors._classification.KNeighborsClassifier'>: 1.107900857925415, <class 'sklearn.tree._classes.DecisionTreeClassifier'>: 2.887955904006958, <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>: 92.74761509895325}\n","\n","\n","Dataset forest_covertypes: \n","Best Estimator: <class 'sklearn.neighbors._classification.KNeighborsClassifier'> \n"," Params: {'n_neighbors': 4, 'leaf_size': 27.523529337036408} \n","Score: 0.7833333333333333 \n","Total time:2168.0332849025726 \n","Testing score:0.814 \n","Time Dict:{<class 'sklearn.linear_model._logistic.LogisticRegression'>: 1836.6486015319824, <class 'sklearn.neighbors._classification.KNeighborsClassifier'>: 68.66654872894287, <class 'sklearn.tree._classes.DecisionTreeClassifier'>: 27.819358348846436, <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>: 234.8987762928009}\n","\n","\n","Dataset kepler_exoplanets: \n","Best Estimator: <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> \n"," Params: {'n_estimators': 85, 'learning_rate': 0.6614545159006884} \n","Score: 0.98562296472228 \n","Total time:816.5169985294342 \n","Testing score:0.9832723470987977 \n","Time Dict:{<class 'sklearn.linear_model._logistic.LogisticRegression'>: 160.8361792564392, <class 'sklearn.neighbors._classification.KNeighborsClassifier'>: 15.471468210220337, <class 'sklearn.tree._classes.DecisionTreeClassifier'>: 48.32480335235596, <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>: 591.8845477104187}\n","\n","\n","Grid Search total time: 3126.927972793579\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mnist</th>\n","      <th>forest_covertypes</th>\n","      <th>kepler_exoplanets</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>&lt;class 'sklearn.linear_model._logistic.LogisticRegression'&gt;</th>\n","      <td>{'best_score': 0.9554627696590119, 'best_param...</td>\n","      <td>{'best_score': 0.6371666666666665, 'best_param...</td>\n","      <td>{'best_score': 0.7529719730568302, 'best_param...</td>\n","    </tr>\n","    <tr>\n","      <th>&lt;class 'sklearn.neighbors._classification.KNeighborsClassifier'&gt;</th>\n","      <td>{'best_score': 0.9805149617258176, 'best_param...</td>\n","      <td>{'best_score': 0.7833333333333333, 'best_param...</td>\n","      <td>{'best_score': 0.7551959375152125, 'best_param...</td>\n","    </tr>\n","    <tr>\n","      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n","      <td>{'best_score': 0.8343771746694503, 'best_param...</td>\n","      <td>{'best_score': 0.7625000000000001, 'best_param...</td>\n","      <td>{'best_score': 0.9792184021132301, 'best_param...</td>\n","    </tr>\n","    <tr>\n","      <th>&lt;class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'&gt;</th>\n","      <td>{'best_score': 0.6931106471816285, 'best_param...</td>\n","      <td>{'best_score': 0.43566666666666665, 'best_para...</td>\n","      <td>{'best_score': 0.98562296472228, 'best_params'...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                mnist  \\\n","<class 'sklearn.linear_model._logistic.Logistic...  {'best_score': 0.9554627696590119, 'best_param...   \n","<class 'sklearn.neighbors._classification.KNeig...  {'best_score': 0.9805149617258176, 'best_param...   \n","<class 'sklearn.tree._classes.DecisionTreeClass...  {'best_score': 0.8343771746694503, 'best_param...   \n","<class 'sklearn.ensemble._weight_boosting.AdaBo...  {'best_score': 0.6931106471816285, 'best_param...   \n","\n","                                                                                    forest_covertypes  \\\n","<class 'sklearn.linear_model._logistic.Logistic...  {'best_score': 0.6371666666666665, 'best_param...   \n","<class 'sklearn.neighbors._classification.KNeig...  {'best_score': 0.7833333333333333, 'best_param...   \n","<class 'sklearn.tree._classes.DecisionTreeClass...  {'best_score': 0.7625000000000001, 'best_param...   \n","<class 'sklearn.ensemble._weight_boosting.AdaBo...  {'best_score': 0.43566666666666665, 'best_para...   \n","\n","                                                                                    kepler_exoplanets  \n","<class 'sklearn.linear_model._logistic.Logistic...  {'best_score': 0.7529719730568302, 'best_param...  \n","<class 'sklearn.neighbors._classification.KNeig...  {'best_score': 0.7551959375152125, 'best_param...  \n","<class 'sklearn.tree._classes.DecisionTreeClass...  {'best_score': 0.9792184021132301, 'best_param...  \n","<class 'sklearn.ensemble._weight_boosting.AdaBo...  {'best_score': 0.98562296472228, 'best_params'...  "]},"metadata":{"tags":[]},"execution_count":17}]}]}